{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import *\n",
    "from dataset import TimeSeriesDataset\n",
    "from models.transformer import TransformerClassifier\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(ratio, scaler_type=\"standard\"):\n",
    "    seed_everything(43)\n",
    "\n",
    "    # Load configuration\n",
    "    hyperparams = load_config(\"transformer\")\n",
    "\n",
    "    # Unpack hyperparameters\n",
    "    threshold = hyperparams[\"threshold\"]\n",
    "    window_minutes = hyperparams[\"window_minutes\"]\n",
    "    stride_minutes = hyperparams[\"stride_minutes\"]\n",
    "    length = hyperparams[\"length\"]\n",
    "    batch_size = hyperparams[\"batch_size\"]\n",
    "    dim = hyperparams[\"dim\"]\n",
    "    num_heads = hyperparams[\"num_heads\"]\n",
    "    hidden_dim = hyperparams[\"hidden_dim\"]\n",
    "    num_layers = hyperparams[\"num_layers\"]\n",
    "    learning_rate = hyperparams[\"learning_rate\"]\n",
    "    epochs = hyperparams[\"epochs\"]\n",
    "\n",
    "    # Read data\n",
    "    full_path = os.getcwd()\n",
    "    data_path = os.path.join(full_path, 'data', '경진대회용 주조 공정최적화 데이터셋.csv')\n",
    "    data = pd.read_csv(data_path, encoding='cp949')\n",
    "\n",
    "    # Preprocess\n",
    "    data = preprocess(data)\n",
    "    data_time_series = make_time_series(data, time_threshold=3000)  # 3000초 => 50분\n",
    "    data_time_series = preprocess_time_series(data_time_series)\n",
    "\n",
    "    # Split\n",
    "    train, valid, test = split_by_process(data_time_series)\n",
    "    train, valid, test = interpolate(train, valid, test)\n",
    "\n",
    "    # Apply scaler\n",
    "    scaler = apply_scaler(train, scaler_type=scaler_type)\n",
    "\n",
    "    train_dataset = TimeSeriesDataset(train, scaler=scaler, threshold=threshold, window_minutes=window_minutes, stride_minutes=stride_minutes, length=length, undersampling=True, ratio=ratio)\n",
    "    valid_dataset = TimeSeriesDataset(valid, scaler=scaler, threshold=threshold, window_minutes=window_minutes, stride_minutes=stride_minutes, length=length)\n",
    "    test_dataset = TimeSeriesDataset(test, scaler=scaler, threshold=threshold, window_minutes=window_minutes, stride_minutes=stride_minutes, length=length)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Model, optimizer, loss, trainer\n",
    "    model = TransformerClassifier(input_dim=dim, num_heads=num_heads, hidden_dim=hidden_dim, num_layers=num_layers)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "    trainer = Trainer(model=model, optimizer=optimizer, loss_fn=cross_entropy_loss, save_model_path='model_saved_dl/transformer.pth')\n",
    "\n",
    "    # Train\n",
    "    trainer.fit(train_loader, valid_loader, epochs=epochs)\n",
    "\n",
    "    # Infer\n",
    "    trainer.evaluate_metrics(test_loader, model_path='model_saved_dl/transformer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(ratio=5.0, scaler_type=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
